{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\antho\\anaconda3\\lib\\site-packages (3.10.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: torch in c:\\users\\antho\\anaconda3\\lib\\site-packages (2.8.0+cpu)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\antho\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\antho\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\antho\\anaconda3\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\antho\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\antho\\anaconda3\\lib\\site-packages (from matplotlib) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\antho\\anaconda3\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\antho\\anaconda3\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\antho\\anaconda3\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\antho\\anaconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: filelock in c:\\users\\antho\\anaconda3\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\antho\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\antho\\anaconda3\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\antho\\anaconda3\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\antho\\anaconda3\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\antho\\anaconda3\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\antho\\anaconda3\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\antho\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\antho\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\antho\\anaconda3\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\antho\\anaconda3\\lib\\site-packages (1.15.3)\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in c:\\users\\antho\\anaconda3\\lib\\site-packages (from scipy) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parses the rollout data from demo.py and saves them as numpy arrays of states, actions, and pot handle positions (the conditional vector data)\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "import torch\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from transform_utils import quat_to_rot6d, rotvec_to_rot6d, rot6d_to_quat\n",
    "from image_encoder import VisionTransformerEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformerEncoder(\n",
       "  (patch_embed): ImagePatchAndEmbed(\n",
       "    (projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (blocks): ModuleList(\n",
       "    (0-11): 12 x TransformerBlock(\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): MultiHeadAttention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (4): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (head): Linear(in_features=768, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize ViT encoder for image processing\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "vit_encoder = VisionTransformerEncoder(latent_dim=128)\n",
    "vit_encoder.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"rollouts_pot/rollout_seed0_mode2.pkl\", \"rb\") as f:\n",
    "#     rollout = pkl.load(f)\n",
    "#     obs = rollout[\"observations\"]\n",
    "#     actions = np.array(rollout[\"actions\"])\n",
    "#     robot0_eef_pos = np.array([o[\"robot0_eef_pos\"] for o in obs])\n",
    "#     robot0_eef_quat = np.array([o[\"robot0_eef_quat\"] for o in obs])\n",
    "#     robot0_gripper_pos = np.array([o[\"robot0_gripper_pos\"] for o in obs])\n",
    "#     robot1_eef_pos = np.array([o[\"robot1_eef_pos\"] for o in obs])\n",
    "#     robot1_eef_quat = np.array([o[\"robot1_eef_quat\"] for o in obs])\n",
    "#     robot1_gripper_pos = np.array([o[\"robot1_gripper_pos\"] for o in obs])\n",
    "\n",
    "#     repeats_needed = 250 - actions.shape[0]\n",
    "\n",
    "#     repeated_last = np.tile(actions[-1], (repeats_needed, 1))\n",
    "#     actions = np.vstack([actions, repeated_last])\n",
    "\n",
    "#     repeated_last = np.tile(robot0_eef_pos[-1], (repeats_needed, 1))\n",
    "#     robot0_eef_pos = np.vstack([robot0_eef_pos, repeated_last])\n",
    "#     state = robot0_eef_pos\n",
    "\n",
    "#     repeated_last = np.tile(robot0_eef_quat[-1], (repeats_needed, 1))\n",
    "#     robot0_eef_quat = np.vstack([robot0_eef_quat, repeated_last])\n",
    "#     robot0_eef_rotvec = R.from_quat(robot0_eef_quat).as_rotvec()\n",
    "#     state = np.hstack([state, robot0_eef_rotvec])\n",
    "\n",
    "\n",
    "#     repeated_last = np.tile(robot0_gripper_pos[-1], (repeats_needed, 1))\n",
    "#     robot0_gripper_pos = robot0_gripper_pos.reshape(-1, 1)\n",
    "#     robot0_gripper_pos = np.vstack([robot0_gripper_pos, repeated_last])\n",
    "#     state = np.hstack([state, robot0_gripper_pos])\n",
    "\n",
    "#     repeated_last = np.tile(robot1_eef_pos[-1], (repeats_needed, 1))\n",
    "#     robot1_eef_pos = np.vstack([robot1_eef_pos, repeated_last])\n",
    "#     state = np.hstack([state, robot1_eef_pos])\n",
    "\n",
    "#     repeated_last = np.tile(robot1_eef_quat[-1], (repeats_needed, 1))\n",
    "#     robot1_eef_quat = np.vstack([robot1_eef_quat, repeated_last])\n",
    "#     robot1_eef_rotvec = R.from_quat(robot1_eef_quat).as_rotvec()\n",
    "#     state = np.hstack([state, robot1_eef_rotvec])\n",
    "\n",
    "#     repeated_last = np.tile(robot1_gripper_pos[-1], (repeats_needed, 1))\n",
    "#     robot1_gripper_pos = robot1_gripper_pos.reshape(-1, 1)\n",
    "#     robot1_gripper_pos = np.vstack([robot1_gripper_pos, repeated_last])\n",
    "#     state = np.hstack([state, robot1_gripper_pos])\n",
    "\n",
    "# print(np.shape(state))\n",
    "# print(np.shape(actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(649, 14)\n",
      "here\n",
      "Processing 649 frames with BATCH processing...\n",
      "  Batch 1/82: frames 0-8\n",
      "  Batch 2/82: frames 8-16\n",
      "  Batch 3/82: frames 16-24\n",
      "  Batch 4/82: frames 24-32\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 50\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     49\u001b[0m     batch_latents0 \u001b[38;5;241m=\u001b[39m vit_encoder(batch_imgs0)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m---> 50\u001b[0m     batch_latents1 \u001b[38;5;241m=\u001b[39m vit_encoder(batch_imgs1)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     51\u001b[0m     camera0_latents\u001b[38;5;241m.\u001b[39mextend(batch_latents0)\n\u001b[0;32m     52\u001b[0m     camera1_latents\u001b[38;5;241m.\u001b[39mextend(batch_latents1)\n",
      "File \u001b[1;32mc:\\Users\\antho\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\antho\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Documents\\Berkeley\\BAIR_ICON\\CTDE_Diffusion\\arm\\lift\\image_encoder.py:141\u001b[0m, in \u001b[0;36mVisionTransformerEncoder.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    139\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m--> 141\u001b[0m     x \u001b[38;5;241m=\u001b[39m block(x)\n\u001b[0;32m    142\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x)\n\u001b[0;32m    143\u001b[0m latent_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead(x[:, \u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\antho\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\antho\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Documents\\Berkeley\\BAIR_ICON\\CTDE_Diffusion\\arm\\lift\\image_encoder.py:102\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    101\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x))\n\u001b[1;32m--> 102\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x))\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\antho\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\antho\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\antho\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:244\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 244\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\antho\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\antho\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\antho\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "expert_states_list = []\n",
    "expert_actions_list = []\n",
    "pot_start_list = []\n",
    "pot_states_list1 = []\n",
    "pot_states_list2 = []\n",
    "image_latents_list0 = []\n",
    "image_latents_list1 = []\n",
    "for i in [2, 3]:\n",
    "    for j in [0]:  # Only process seed 0 since we only have those files   \n",
    "        with open(\"rollouts/newslower/rollout_seed%s_mode%s.pkl\" % (j, i), \"rb\") as f: #CHANGE ME! - USE SEED 100 ONLY FOR TESTING PURPOSES, AND CHANGE THE FILE NAME TO WHAT IT IS ON MACHINE.\n",
    "            rollout = pkl.load(f)\n",
    "            obs = rollout[\"observations\"]\n",
    "            actions = np.array(rollout[\"actions\"])\n",
    "            print(np.shape(actions))\n",
    "            pot1 = np.array(rollout[\"pot_states1\"])\n",
    "            pot2 = np.array(rollout[\"pot_states2\"])\n",
    "            pot = np.array(rollout[\"pot_start\"])\n",
    "\n",
    "            pot_start_list.append(np.concatenate((pot[0], pot[1])))\n",
    "\n",
    "            print(\"here\")\n",
    "\n",
    "            if 'camera0_obs' in rollout and 'camera1_obs' in rollout:\n",
    "                camera0_latents = []\n",
    "                camera1_latents = []\n",
    "                for frame_idx in range(len(rollout['camera0_obs'])):\n",
    "                    print(f\"Processing frame {frame_idx} of {len(rollout['camera0_obs'])}\")\n",
    "                    img0 = torch.from_numpy(rollout['camera0_obs'][frame_idx]).permute(2,0,1).unsqueeze(0).float().to(device)\n",
    "                    img1 = torch.from_numpy(rollout['camera1_obs'][frame_idx]).permute(2,0,1).unsqueeze(0).float().to(device)\n",
    "                    with torch.no_grad():\n",
    "                        camera0_latents.append(vit_encoder(img0).cpu().numpy().squeeze())\n",
    "                        camera1_latents.append(vit_encoder(img1).cpu().numpy().squeeze())\n",
    "                camera0_latents = np.array(camera0_latents)\n",
    "                camera1_latents = np.array(camera1_latents)\n",
    "            else:\n",
    "                camera0_latents = np.zeros((len(actions), 128))\n",
    "                camera1_latents = np.zeros((len(actions), 128))\n",
    "\n",
    "            print(\"processing rollout\")\n",
    "\n",
    "            robot0_eef_pos = np.array([o[\"robot0_eef_pos\"] for o in obs])\n",
    "            robot0_eef_quat = np.array([o[\"robot0_eef_quat_site\"] for o in obs])\n",
    "            robot0_gripper_pos = np.array([o[\"robot0_gripper_pos\"] for o in obs])\n",
    "            robot1_eef_pos = np.array([o[\"robot1_eef_pos\"] for o in obs])\n",
    "            robot1_eef_quat = np.array([o[\"robot1_eef_quat_site\"] for o in obs])\n",
    "            robot1_gripper_pos = np.array([o[\"robot1_gripper_pos\"] for o in obs])\n",
    "\n",
    "            repeats_needed = 700 - actions.shape[0]\n",
    "\n",
    "            repeated_last = np.tile(actions[-1], (repeats_needed, 1))\n",
    "            actions = np.vstack([actions, repeated_last])\n",
    "\n",
    "            repeated_last = np.tile(robot0_eef_pos[-1], (repeats_needed, 1))\n",
    "            robot0_eef_pos = np.vstack([robot0_eef_pos, repeated_last])\n",
    "            state = robot0_eef_pos\n",
    "\n",
    "            print(\"processing rollout\")\n",
    "\n",
    "            repeated_last = np.tile(robot0_eef_quat[-1], (repeats_needed, 1))\n",
    "            robot0_eef_quat = np.vstack([robot0_eef_quat, repeated_last])\n",
    "            robot0_eef_rotvec = R.from_quat(robot0_eef_quat).as_rotvec()\n",
    "            state = np.hstack([state, robot0_eef_rotvec])\n",
    "\n",
    "\n",
    "            repeated_last = np.tile(robot0_gripper_pos[-1], (repeats_needed, 1))\n",
    "            robot0_gripper_pos = robot0_gripper_pos.reshape(-1, 1)\n",
    "            robot0_gripper_pos = np.vstack([robot0_gripper_pos, repeated_last])\n",
    "            state = np.hstack([state, robot0_gripper_pos])\n",
    "\n",
    "            repeated_last = np.tile(robot1_eef_pos[-1], (repeats_needed, 1))\n",
    "            robot1_eef_pos = np.vstack([robot1_eef_pos, repeated_last])\n",
    "            state = np.hstack([state, robot1_eef_pos])\n",
    "\n",
    "            print(\"processing rollout\")\n",
    "\n",
    "            repeated_last = np.tile(robot1_eef_quat[-1], (repeats_needed, 1))\n",
    "            robot1_eef_quat = np.vstack([robot1_eef_quat, repeated_last])\n",
    "            robot1_eef_rotvec = R.from_quat(robot1_eef_quat).as_rotvec()\n",
    "            state = np.hstack([state, robot1_eef_rotvec])\n",
    "\n",
    "            repeated_last = np.tile(robot1_gripper_pos[-1], (repeats_needed, 1))\n",
    "            robot1_gripper_pos = robot1_gripper_pos.reshape(-1, 1)\n",
    "            robot1_gripper_pos = np.vstack([robot1_gripper_pos, repeated_last])\n",
    "            state = np.hstack([state, robot1_gripper_pos])\n",
    "\n",
    "            repeated_last = np.tile(pot1[-1], (repeats_needed, 1))\n",
    "            pot1 = np.vstack([pot1, repeated_last])\n",
    "            repeated_last = np.tile(pot2[-1], (repeats_needed, 1))\n",
    "            pot2 = np.vstack([pot2, repeated_last])\n",
    "            pot_states_list1.append(pot1)\n",
    "            pot_states_list2.append(pot2)\n",
    "\n",
    "            repeated_last = np.tile(camera0_latents[-1], (repeats_needed, 1))\n",
    "            camera0_latents = np.vstack([camera0_latents, repeated_last])\n",
    "            repeated_last = np.tile(camera1_latents[-1], (repeats_needed, 1))\n",
    "            camera1_latents = np.vstack([camera1_latents, repeated_last])\n",
    "            image_latents_list0.append(camera0_latents)\n",
    "            image_latents_list1.append(camera1_latents)\n",
    "\n",
    "            print(\"processing rollout\")\n",
    "\n",
    "            expert_states_list.append(state)\n",
    "            expert_actions_list.append(actions)\n",
    "\n",
    "            print(\"moving on...\")\n",
    "\n",
    "expert_states_rotvec = np.stack(expert_states_list, axis=0)\n",
    "expert_actions_rotvec = np.stack(expert_actions_list, axis=0)\n",
    "pot_states_rotvec1 = np.stack(pot_states_list1, axis=0)\n",
    "pot_states_rotvec2 = np.stack(pot_states_list2, axis=0)\n",
    "pot_start_rotvec = np.stack(pot_start_list, axis=0)\n",
    "image_latents_rotvec0 = np.stack(image_latents_list0, axis=0)\n",
    "image_latents_rotvec1 = np.stack(image_latents_list1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 700, 14)\n",
      "(20, 700, 14)\n",
      "(20, 700, 3)\n",
      "(20, 700, 3)\n",
      "(20, 6)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(expert_states_rotvec))\n",
    "print(np.shape(expert_actions_rotvec))\n",
    "print(np.shape(pot_states_rotvec1))\n",
    "print(np.shape(pot_states_rotvec2))\n",
    "print(np.shape(pot_start_rotvec))\n",
    "print(np.shape(image_latents_rotvec0))\n",
    "print(np.shape(image_latents_rotvec1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"data/expert_states_newslower_20.npy\", expert_states_rotvec)\n",
    "np.save(\"data/expert_actions_newslower_20.npy\", expert_actions_rotvec)\n",
    "np.save(\"data/pot_states1_newslower_20.npy\", pot_states_rotvec1)\n",
    "np.save(\"data/pot_states2_newslower_20.npy\", pot_states_rotvec2)\n",
    "np.save(\"data/pot_start_newslower_20.npy\", pot_start_rotvec)\n",
    "np.save(\"data/arm1_images_latents.npy\", image_latents_rotvec0)\n",
    "np.save(\"data/arm2_images_latents.npy\", image_latents_rotvec1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"rollouts/rollout_seed0_mode2.pkl\", \"rb\") as f:\n",
    "#     rollout = pkl.load(f)\n",
    "#     obs = rollout[\"observations\"]\n",
    "#     actions = np.array(rollout[\"actions\"])\n",
    "\n",
    "#     pos0 = actions[:,:3]\n",
    "#     rotvec0 = actions[:,3:6]\n",
    "#     gripper0 = actions[:,6]\n",
    "#     pos1 = actions[:,7:10]\n",
    "#     rotvec1 = actions[:,10:13]\n",
    "#     gripper1 = actions[:,13]\n",
    "\n",
    "#     rot6d_list0 = []\n",
    "#     for rv in rotvec0:\n",
    "#         rot6d_list0.append(rotvec_to_rot6d(rv))\n",
    "#     rot6d0 = np.array(rot6d_list0)\n",
    "\n",
    "#     rot6d_list1 = []\n",
    "#     for rv in rotvec1:\n",
    "#         rot6d_list1.append(rotvec_to_rot6d(rv))\n",
    "#     rot6d1 = np.array(rot6d_list1)\n",
    "\n",
    "#     actions = np.concatenate((pos0, rot6d0, gripper0.reshape(-1, 1), pos1, rot6d1, gripper1.reshape(-1, 1)), axis=1)\n",
    "\n",
    "#     robot0_eef_pos = np.array([o[\"robot0_eef_pos\"] for o in obs])\n",
    "#     robot0_eef_quat = np.array([o[\"robot0_eef_quat\"] for o in obs])\n",
    "#     robot0_gripper_pos = np.array([o[\"robot0_gripper_pos\"] for o in obs])\n",
    "#     robot1_eef_pos = np.array([o[\"robot1_eef_pos\"] for o in obs])\n",
    "#     robot1_eef_quat = np.array([o[\"robot1_eef_quat\"] for o in obs])\n",
    "#     robot1_gripper_pos = np.array([o[\"robot1_gripper_pos\"] for o in obs])\n",
    "\n",
    "#     repeats_needed = 250 - actions.shape[0]\n",
    "\n",
    "#     repeated_last = np.tile(actions[-1], (repeats_needed, 1))\n",
    "#     actions = np.vstack([actions, repeated_last])\n",
    "\n",
    "#     repeated_last = np.tile(robot0_eef_pos[-1], (repeats_needed, 1))\n",
    "#     robot0_eef_pos = np.vstack([robot0_eef_pos, repeated_last])\n",
    "#     state = robot0_eef_pos\n",
    "\n",
    "#     repeated_last = np.tile(robot0_eef_quat[-1], (repeats_needed, 1))\n",
    "#     robot0_eef_quat = np.vstack([robot0_eef_quat, repeated_last])\n",
    "#     eef_rot6d0 = []\n",
    "#     for q in robot0_eef_quat:\n",
    "#         eef_rot6d0.append(quat_to_rot6d(q))\n",
    "#     robot0_eef_rot6d = np.array(eef_rot6d0)\n",
    "#     state = np.hstack([state, robot0_eef_rot6d])\n",
    "\n",
    "\n",
    "#     repeated_last = np.tile(robot0_gripper_pos[-1], (repeats_needed, 1))\n",
    "#     robot0_gripper_pos = robot0_gripper_pos.reshape(-1, 1)\n",
    "#     robot0_gripper_pos = np.vstack([robot0_gripper_pos, repeated_last])\n",
    "#     state = np.hstack([state, robot0_gripper_pos])\n",
    "\n",
    "#     repeated_last = np.tile(robot1_eef_pos[-1], (repeats_needed, 1))\n",
    "#     robot1_eef_pos = np.vstack([robot1_eef_pos, repeated_last])\n",
    "#     state = np.hstack([state, robot1_eef_pos])\n",
    "\n",
    "#     repeated_last = np.tile(robot1_eef_quat[-1], (repeats_needed, 1))\n",
    "#     robot1_eef_quat = np.vstack([robot1_eef_quat, repeated_last])\n",
    "#     eef_rot6d1 = []\n",
    "#     for q in robot1_eef_quat:\n",
    "#         eef_rot6d1.append(quat_to_rot6d(q))\n",
    "#     robot1_eef_rot6d = np.array(eef_rot6d1)\n",
    "#     state = np.hstack([state, robot1_eef_rot6d])\n",
    "\n",
    "#     repeated_last = np.tile(robot1_gripper_pos[-1], (repeats_needed, 1))\n",
    "#     robot1_gripper_pos = robot1_gripper_pos.reshape(-1, 1)\n",
    "#     robot1_gripper_pos = np.vstack([robot1_gripper_pos, repeated_last])\n",
    "#     state = np.hstack([state, robot1_gripper_pos])\n",
    "    \n",
    "# print(np.shape(state))\n",
    "# print(np.shape(actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_states_list = []\n",
    "expert_actions_list = []\n",
    "pot_states_list = []\n",
    "for i in [2, 3]:\n",
    "    for j in range(10):   \n",
    "        with open(\"rollouts_grippause/rollout_seed%s_mode%s.pkl\" % (j*10, i), \"rb\") as f:\n",
    "            rollout = pkl.load(f)\n",
    "            obs = rollout[\"observations\"]\n",
    "            actions = np.array(rollout[\"actions\"])\n",
    "            pot = np.array(rollout[\"pot_pos\"])\n",
    "\n",
    "            pot_states_list.append(np.concatenate((pot[0], pot[1])))\n",
    "\n",
    "            pos0 = actions[:,:3]\n",
    "            rotvec0 = actions[:,3:6]\n",
    "            gripper0 = actions[:,6]\n",
    "            pos1 = actions[:,7:10]\n",
    "            rotvec1 = actions[:,10:13]\n",
    "            gripper1 = actions[:,13]\n",
    "\n",
    "            rot6d_list0 = []\n",
    "            for rv in rotvec0:\n",
    "                rot6d_list0.append(rotvec_to_rot6d(rv))\n",
    "            rot6d0 = np.array(rot6d_list0)\n",
    "\n",
    "            rot6d_list1 = []\n",
    "            for rv in rotvec1:\n",
    "                rot6d_list1.append(rotvec_to_rot6d(rv))\n",
    "            rot6d1 = np.array(rot6d_list1)\n",
    "\n",
    "            actions = np.concatenate((pos0, rot6d0, gripper0.reshape(-1, 1), pos1, rot6d1, gripper1.reshape(-1, 1)), axis=1)\n",
    "\n",
    "            robot0_eef_pos = np.array([o[\"robot0_eef_pos\"] for o in obs])\n",
    "            robot0_eef_quat = np.array([o[\"robot0_eef_quat_site\"] for o in obs])\n",
    "            robot0_gripper_pos = np.array([o[\"robot0_gripper_pos\"] for o in obs])\n",
    "            robot1_eef_pos = np.array([o[\"robot1_eef_pos\"] for o in obs])\n",
    "            robot1_eef_quat = np.array([o[\"robot1_eef_quat_site\"] for o in obs])\n",
    "            robot1_gripper_pos = np.array([o[\"robot1_gripper_pos\"] for o in obs])\n",
    "\n",
    "            repeats_needed = 400 - actions.shape[0]\n",
    "\n",
    "            repeated_last = np.tile(actions[-1], (repeats_needed, 1))\n",
    "            actions = np.vstack([actions, repeated_last])\n",
    "\n",
    "            repeated_last = np.tile(robot0_eef_pos[-1], (repeats_needed, 1))\n",
    "            robot0_eef_pos = np.vstack([robot0_eef_pos, repeated_last])\n",
    "            state = robot0_eef_pos\n",
    "\n",
    "            repeated_last = np.tile(robot0_eef_quat[-1], (repeats_needed, 1))\n",
    "            robot0_eef_quat = np.vstack([robot0_eef_quat, repeated_last])\n",
    "            eef_rot6d0 = []\n",
    "            for q in robot0_eef_quat:\n",
    "                eef_rot6d0.append(quat_to_rot6d(q))\n",
    "            robot0_eef_rot6d = np.array(eef_rot6d0)\n",
    "            state = np.hstack([state, robot0_eef_rot6d])\n",
    "\n",
    "\n",
    "            repeated_last = np.tile(robot0_gripper_pos[-1], (repeats_needed, 1))\n",
    "            robot0_gripper_pos = robot0_gripper_pos.reshape(-1, 1)\n",
    "            robot0_gripper_pos = np.vstack([robot0_gripper_pos, repeated_last])\n",
    "            state = np.hstack([state, robot0_gripper_pos])\n",
    "\n",
    "            repeated_last = np.tile(robot1_eef_pos[-1], (repeats_needed, 1))\n",
    "            robot1_eef_pos = np.vstack([robot1_eef_pos, repeated_last])\n",
    "            state = np.hstack([state, robot1_eef_pos])\n",
    "\n",
    "            repeated_last = np.tile(robot1_eef_quat[-1], (repeats_needed, 1))\n",
    "            robot1_eef_quat = np.vstack([robot1_eef_quat, repeated_last])\n",
    "            eef_rot6d1 = []\n",
    "            for q in robot1_eef_quat:\n",
    "                eef_rot6d1.append(quat_to_rot6d(q))\n",
    "            robot1_eef_rot6d = np.array(eef_rot6d1)\n",
    "            state = np.hstack([state, robot1_eef_rot6d])\n",
    "\n",
    "            repeated_last = np.tile(robot1_gripper_pos[-1], (repeats_needed, 1))\n",
    "            robot1_gripper_pos = robot1_gripper_pos.reshape(-1, 1)\n",
    "            robot1_gripper_pos = np.vstack([robot1_gripper_pos, repeated_last])\n",
    "            state = np.hstack([state, robot1_gripper_pos])\n",
    "\n",
    "            expert_states_list.append(state)\n",
    "            expert_actions_list.append(actions)\n",
    "\n",
    "expert_states_rot6d = np.stack(expert_states_list, axis=0)\n",
    "expert_actions_rot6d = np.stack(expert_actions_list, axis=0)\n",
    "pot_states_rot6d = np.stack(pot_states_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 400, 20)\n",
      "(20, 400, 20)\n",
      "(20, 6)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(expert_states_rot6d))\n",
    "print(np.shape(expert_actions_rot6d))\n",
    "print(np.shape(pot_states_rot6d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"data/expert_states_rot6d_site_grippause_20.npy\", expert_states_rot6d)\n",
    "np.save(\"data/expert_actions_rot6d_site_grippause_20.npy\", expert_actions_rot6d)\n",
    "np.save(\"data/pot_states_rot6d_site_grippause_20.npy\", pot_states_rot6d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
