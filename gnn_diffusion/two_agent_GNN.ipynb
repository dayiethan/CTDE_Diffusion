{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 9, 2]) torch.Size([10000, 9, 2]) torch.Size([10000, 4]) torch.Size([10000, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GraphConv\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import numpy as np\n",
    "from utils import Normalizer, set_seed\n",
    "from conditional_Action_DiT import Conditional_ODE\n",
    "import matplotlib.pyplot as plt\n",
    "from discrete import *\n",
    "import sys\n",
    "import pdb\n",
    "import csv\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Parameters\n",
    "n_gradient_steps = 100_000\n",
    "batch_size = 64\n",
    "model_size = {\"d_model\": 256, \"n_heads\": 4, \"depth\": 3}\n",
    "H = 10 # horizon, length of each trajectory\n",
    "\n",
    "# Define initial and final points, and a single central obstacle\n",
    "initial_point_up = np.array([0.0, 0.0])\n",
    "final_point_up = np.array([20.0, 0.0])\n",
    "final_point_down = np.array([0.0, 0.0])\n",
    "initial_point_down = np.array([20.0, 0.0])\n",
    "obstacle = (10, 0, 4.0) \n",
    "\n",
    "# Loading training trajectories\n",
    "all_points1 = []    # want modes 1, 2, 4, 6\n",
    "all_points2 = []    # want modes 1, 2, 3, 5\n",
    "with open('data/trajs_noise1.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        x1, y1 = float(row[4]), float(row[5])\n",
    "        x2, y2 = float(row[7]), float(row[8])\n",
    "        all_points1.append([x1, y1])\n",
    "        all_points2.append([x2, y2])\n",
    "\n",
    "num_trajectories = 10000\n",
    "points_per_trajectory = 10\n",
    "\n",
    "expert_data1 = [\n",
    "    all_points1[i * points_per_trajectory:(i + 1) * points_per_trajectory]\n",
    "    for i in range(num_trajectories)\n",
    "]\n",
    "first_trajectory1 = expert_data1[0]\n",
    "x1 = [point[0] for point in first_trajectory1]\n",
    "y1 = [point[1] for point in first_trajectory1]\n",
    "\n",
    "expert_data2 = [\n",
    "    all_points2[i * points_per_trajectory:(i + 1) * points_per_trajectory]\n",
    "    for i in range(num_trajectories)\n",
    "]\n",
    "first_trajectory2 = expert_data2[0]\n",
    "x2 = [point[0] for point in first_trajectory2]\n",
    "y2 = [point[1] for point in first_trajectory2]\n",
    "\n",
    "\n",
    "expert_data1 = np.array(expert_data1)\n",
    "expert_data2 = np.array(expert_data2)\n",
    "\n",
    "\n",
    "# Unspliced trajectories to get final positions\n",
    "orig1 = [\n",
    "    all_points1[i * 100:(i + 1) * 100]\n",
    "    for i in range(1000)\n",
    "]\n",
    "orig2 = [\n",
    "    all_points2[i * 100:(i + 1) * 100]\n",
    "    for i in range(1000)\n",
    "]\n",
    "orig1 = np.array(orig1)\n",
    "orig2 = np.array(orig2)\n",
    "\n",
    "combined_data1 = np.concatenate((expert_data1, expert_data2), axis=0)\n",
    "combined_data2 = np.concatenate((orig1, orig2), axis=0)\n",
    "mean1 = np.mean(combined_data1, axis=(0,1))\n",
    "std1 = np.std(combined_data1, axis=(0,1))\n",
    "mean2 = np.mean(combined_data2, axis=(0,1))\n",
    "std2 = np.std(combined_data2, axis=(0,1))\n",
    "mean = (mean1 + mean2)/2\n",
    "std = (std1 + std2)/2\n",
    "expert_data1 = (expert_data1 - mean) / std\n",
    "expert_data2 = (expert_data2 - mean) / std\n",
    "orig1 = (orig1 - mean) / std\n",
    "orig2 = (orig2 - mean) / std\n",
    "\n",
    "\n",
    "\n",
    "# Define environment\n",
    "class TwoUnicycle():\n",
    "    def __init__(self, state_size=2, action_size=2):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.name = \"TwoUnicycle\"\n",
    "env = TwoUnicycle()\n",
    "\n",
    "\n",
    "\n",
    "# Setting up training data\n",
    "obs_init1 = expert_data1[:, 0, :]\n",
    "obs_init2 = expert_data2[:, 0, :]\n",
    "obs_final1 = np.repeat(orig1[:, -1, :], repeats=10, axis=0)\n",
    "obs_final2 = np.repeat(orig2[:, -1, :], repeats=10, axis=0)\n",
    "obs1 = np.hstack([obs_init1, obs_final1])\n",
    "obs2 = np.hstack([obs_init2, obs_final2])\n",
    "obs_temp1 = obs1\n",
    "obs_temp2 = obs2\n",
    "actions1 = expert_data1[:, :H-1, :]\n",
    "actions2 = expert_data2[:, :H-1, :]\n",
    "obs1 = torch.FloatTensor(obs1).to(device)\n",
    "obs2 = torch.FloatTensor(obs2).to(device)\n",
    "\n",
    "attr1 = obs1\n",
    "attr2 = obs2\n",
    "attr_dim1 = attr1.shape[1]\n",
    "attr_dim2 = attr2.shape[1]\n",
    "assert attr_dim1 == env.state_size * 2\n",
    "assert attr_dim2 == env.state_size * 2\n",
    "\n",
    "actions1 = torch.FloatTensor(actions1).to(device)\n",
    "actions2 = torch.FloatTensor(actions2).to(device)\n",
    "sigma_data1 = actions1.std().item()\n",
    "sigma_data2 = actions2.std().item()\n",
    "sig = np.array([sigma_data1, sigma_data2])\n",
    "\n",
    "\n",
    "print(actions1.shape, actions2.shape, obs1.shape, obs2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings for Agent 1: torch.Size([10000, 4])\n",
      "Embeddings for Agent 2: torch.Size([10000, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GraphConv\n",
    "\n",
    "# Define the GNN model\n",
    "class TwoAgentGNN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(TwoAgentGNN, self).__init__()\n",
    "        self.conv1 = GraphConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GraphConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x  # Output separate embeddings for each agent\n",
    "\n",
    "# Example input dimensions\n",
    "input_dim = 4\n",
    "hidden_dim = 16\n",
    "output_dim = 4\n",
    "\n",
    "# Instantiate the GNN\n",
    "gnn = TwoAgentGNN(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "# Example: obs1 and obs2 with shape (10000, 4)\n",
    "obs1 = torch.randn(10000, 4)  # Replace with actual data\n",
    "obs2 = torch.randn(10000, 4)  # Replace with actual data\n",
    "\n",
    "# Stack observations to form a batch of agent pairs\n",
    "x_batch = torch.cat([obs1, obs2], dim=0)  # Shape: (20000, 4)\n",
    "\n",
    "# Define edge connections (same for all batches)\n",
    "edge_index = torch.tensor([[0, 1], [1, 0]], dtype=torch.long)  # Shape: (2, 2)\n",
    "\n",
    "# Expand edge_index for batch processing\n",
    "batch_size = obs1.shape[0]  # 10000\n",
    "edge_index = edge_index.repeat(1, batch_size)  # Shape: (2, 2 * batch_size)\n",
    "\n",
    "# Adjust node indices for batched graph (ensuring unique node indices per batch)\n",
    "offsets = torch.arange(batch_size) * 2  # Offsets for each batch\n",
    "edge_index = edge_index + offsets.repeat_interleave(2).unsqueeze(0)\n",
    "\n",
    "# Forward pass through GNN\n",
    "embeddings = gnn(x_batch, edge_index)  # Shape: (20000, 4)\n",
    "\n",
    "# Reshape to separate agents\n",
    "embeddings1, embeddings2 = embeddings.chunk(2, dim=0)  # Both shapes: (10000, 4)\n",
    "\n",
    "print(\"Embeddings for Agent 1:\", embeddings1.shape)  # Expected: (10000, 4)\n",
    "print(\"Embeddings for Agent 2:\", embeddings2.shape)  # Expected: (10000, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
