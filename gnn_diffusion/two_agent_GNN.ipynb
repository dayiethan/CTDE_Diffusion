{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 9, 2]) torch.Size([10000, 9, 2]) torch.Size([10000, 4]) torch.Size([10000, 4])\n",
      "(10000, 8)\n",
      "tensor([[-1.5334,  0.0288,  1.5117, -0.1075],\n",
      "        [-1.2252, -0.0133,  1.5117, -0.1075],\n",
      "        [-0.9194, -0.1458,  1.5117, -0.1075],\n",
      "        ...,\n",
      "        [ 0.7165, -0.7212,  1.6371, -0.4495],\n",
      "        [ 1.1704, -0.4807,  1.6371, -0.4495],\n",
      "        [ 1.5265, -0.4524,  1.6371, -0.4495]])\n",
      "tensor([[ 1.5114,  0.0829, -1.5749,  0.0160],\n",
      "        [ 1.1990,  0.1119, -1.5749,  0.0160],\n",
      "        [ 0.8894,  0.2365, -1.5749,  0.0160],\n",
      "        ...,\n",
      "        [-0.6880, -0.7199, -1.6368, -0.4294],\n",
      "        [-1.1700, -0.4413, -1.6368, -0.4294],\n",
      "        [-1.5263, -0.4286, -1.6368, -0.4294]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GraphConv\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import numpy as np\n",
    "from utils import Normalizer, set_seed\n",
    "from conditional_Action_DiT import Conditional_ODE\n",
    "import matplotlib.pyplot as plt\n",
    "from discrete import *\n",
    "import sys\n",
    "import pdb\n",
    "import csv\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Parameters\n",
    "n_gradient_steps = 100_000\n",
    "batch_size = 64\n",
    "model_size = {\"d_model\": 256, \"n_heads\": 4, \"depth\": 3}\n",
    "H = 10 # horizon, length of each trajectory\n",
    "\n",
    "# Define initial and final points, and a single central obstacle\n",
    "initial_point_up = np.array([0.0, 0.0])\n",
    "final_point_up = np.array([20.0, 0.0])\n",
    "final_point_down = np.array([0.0, 0.0])\n",
    "initial_point_down = np.array([20.0, 0.0])\n",
    "obstacle = (10, 0, 4.0) \n",
    "\n",
    "# Loading training trajectories\n",
    "all_points1 = []    # want modes 1, 2, 4, 6\n",
    "all_points2 = []    # want modes 1, 2, 3, 5\n",
    "with open('data/trajs_noise1.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        x1, y1 = float(row[4]), float(row[5])\n",
    "        x2, y2 = float(row[7]), float(row[8])\n",
    "        all_points1.append([x1, y1])\n",
    "        all_points2.append([x2, y2])\n",
    "\n",
    "num_trajectories = 10000\n",
    "points_per_trajectory = 10\n",
    "\n",
    "expert_data1 = [\n",
    "    all_points1[i * points_per_trajectory:(i + 1) * points_per_trajectory]\n",
    "    for i in range(num_trajectories)\n",
    "]\n",
    "first_trajectory1 = expert_data1[0]\n",
    "x1 = [point[0] for point in first_trajectory1]\n",
    "y1 = [point[1] for point in first_trajectory1]\n",
    "\n",
    "expert_data2 = [\n",
    "    all_points2[i * points_per_trajectory:(i + 1) * points_per_trajectory]\n",
    "    for i in range(num_trajectories)\n",
    "]\n",
    "first_trajectory2 = expert_data2[0]\n",
    "x2 = [point[0] for point in first_trajectory2]\n",
    "y2 = [point[1] for point in first_trajectory2]\n",
    "\n",
    "\n",
    "expert_data1 = np.array(expert_data1)\n",
    "expert_data2 = np.array(expert_data2)\n",
    "\n",
    "\n",
    "# Unspliced trajectories to get final positions\n",
    "orig1 = [\n",
    "    all_points1[i * 100:(i + 1) * 100]\n",
    "    for i in range(1000)\n",
    "]\n",
    "orig2 = [\n",
    "    all_points2[i * 100:(i + 1) * 100]\n",
    "    for i in range(1000)\n",
    "]\n",
    "orig1 = np.array(orig1)\n",
    "orig2 = np.array(orig2)\n",
    "\n",
    "combined_data1 = np.concatenate((expert_data1, expert_data2), axis=0)\n",
    "combined_data2 = np.concatenate((orig1, orig2), axis=0)\n",
    "mean1 = np.mean(combined_data1, axis=(0,1))\n",
    "std1 = np.std(combined_data1, axis=(0,1))\n",
    "mean2 = np.mean(combined_data2, axis=(0,1))\n",
    "std2 = np.std(combined_data2, axis=(0,1))\n",
    "mean = (mean1 + mean2)/2\n",
    "std = (std1 + std2)/2\n",
    "expert_data1 = (expert_data1 - mean) / std\n",
    "expert_data2 = (expert_data2 - mean) / std\n",
    "orig1 = (orig1 - mean) / std\n",
    "orig2 = (orig2 - mean) / std\n",
    "\n",
    "\n",
    "\n",
    "# Define environment\n",
    "class TwoUnicycle():\n",
    "    def __init__(self, state_size=2, action_size=2):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.name = \"TwoUnicycle\"\n",
    "env = TwoUnicycle()\n",
    "\n",
    "\n",
    "\n",
    "# Setting up training data\n",
    "obs_init1 = expert_data1[:, 0, :]\n",
    "obs_init2 = expert_data2[:, 0, :]\n",
    "obs_final1 = np.repeat(orig1[:, -1, :], repeats=10, axis=0)\n",
    "obs_final2 = np.repeat(orig2[:, -1, :], repeats=10, axis=0)\n",
    "obs1 = np.hstack([obs_init1, obs_final1])\n",
    "obs2 = np.hstack([obs_init2, obs_final2])\n",
    "obs_temp1 = obs1\n",
    "obs_temp2 = obs2\n",
    "actions1 = expert_data1[:, :H-1, :]\n",
    "actions2 = expert_data2[:, :H-1, :]\n",
    "obs1 = torch.FloatTensor(obs1).to(device)\n",
    "obs2 = torch.FloatTensor(obs2).to(device)\n",
    "\n",
    "attr1 = obs1\n",
    "attr2 = obs2\n",
    "attr_dim1 = attr1.shape[1]\n",
    "attr_dim2 = attr2.shape[1]\n",
    "assert attr_dim1 == env.state_size * 2\n",
    "assert attr_dim2 == env.state_size * 2\n",
    "\n",
    "actions1 = torch.FloatTensor(actions1).to(device)\n",
    "actions2 = torch.FloatTensor(actions2).to(device)\n",
    "sigma_data1 = actions1.std().item()\n",
    "sigma_data2 = actions2.std().item()\n",
    "sig = np.array([sigma_data1, sigma_data2])\n",
    "\n",
    "\n",
    "print(actions1.shape, actions2.shape, obs1.shape, obs2.shape)\n",
    "\n",
    "obs = np.hstack([obs1, obs2])\n",
    "print(obs.shape)\n",
    "\n",
    "print(attr1)\n",
    "print(attr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5334,  0.0288,  1.5117, -0.1075],\n",
      "        [ 1.5114,  0.0829, -1.5749,  0.0160],\n",
      "        [-1.2252, -0.0133,  1.5117, -0.1075],\n",
      "        [ 1.1990,  0.1119, -1.5749,  0.0160]])\n",
      "tensor([[0, 1, 2, 3],\n",
      "        [1, 0, 3, 2]])\n",
      "tensor([[ 0.6959, -1.2399, -0.2546, -0.1693],\n",
      "        [ 0.1026,  0.2029, -1.2488,  0.2709],\n",
      "        [ 0.5578, -1.0204, -0.2243, -0.2247],\n",
      "        [ 0.1587,  0.1068, -1.1228,  0.2588]], grad_fn=<AddBackward0>)\n",
      "tensor([[ 0.6959, -1.2399, -0.2546, -0.1693],\n",
      "        [ 0.5578, -1.0204, -0.2243, -0.2247]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 0.1026,  0.2029, -1.2488,  0.2709],\n",
      "        [ 0.1587,  0.1068, -1.1228,  0.2588]], grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6959, -1.2399, -0.2546, -0.1693],\n",
       "        [ 0.1026,  0.2029, -1.2488,  0.2709]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attr_1 = attributes_list[0][idx].clone()  # (batch_size, attr_dim)\n",
    "# attr_2 = attributes_list[1][idx].clone()  # (batch_size, attr_dim)\n",
    "\n",
    "# --------------------------------\n",
    "# STEP 1: Prepare Input for GNN\n",
    "# --------------------------------\n",
    "\n",
    "attr1 = attr1[:2, :]\n",
    "attr2 = attr2[:2, :]\n",
    "\n",
    "# Stack attr_1 and attr_2 to create a (batch_size, 2, attr_dim) tensor\n",
    "node_features = torch.stack([attr1, attr2], dim=1)  # Shape: (batch_size, 2, attr_dim)\n",
    "\n",
    "# Reshape to (batch_size * 2, attr_dim) for GNN input\n",
    "node_features = node_features.view(-1, attr1.shape[-1])  # Shape: (batch_size * 2, attr_dim)\n",
    "\n",
    "print(node_features)\n",
    "\n",
    "batch_size = 2  # Number of trajectories in the batch\n",
    "\n",
    "edge_index = torch.tensor([[0, 1], [1, 0]], dtype=torch.long)  # Shape: (2, 2)\n",
    "\n",
    "edge_index = edge_index.repeat(1, batch_size)  # Shape: (2, 2 * batch_size)\n",
    "\n",
    "# Adjust node indices for batched graph (ensuring unique node indices per batch)\n",
    "offsets = torch.arange(batch_size) * 2  # Offsets for each batch\n",
    "edge_index = edge_index + offsets.repeat_interleave(2).unsqueeze(0)\n",
    "\n",
    "print(edge_index)\n",
    "\n",
    "# --------------------------------\n",
    "# STEP 2: Pass Through GNN\n",
    "# --------------------------------\n",
    "embeddings = gnn(node_features, edge_index)  # Shape: (batch_size * 2, embedding_dim)\n",
    "\n",
    "print(embeddings)\n",
    "\n",
    "# Reshape back to (batch_size, 2, embedding_dim)\n",
    "embeddings = embeddings.view(batch_size, 2, -1)  # Shape: (batch_size, 2, embedding_dim)\n",
    "# Extract embeddings for each agent\n",
    "embed_1 = embeddings[:, 0, :]  # Shape: (batch_size, embedding_dim)\n",
    "embed_2 = embeddings[:, 1, :]  # Shape: (batch_size, embedding_dim)\n",
    "\n",
    "print(embed_1)\n",
    "print(embed_2)\n",
    "\n",
    "gnn(node_features[:2,:],torch.tensor([[0, 1], [1, 0]], dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0591, -1.0592,  0.8310,  0.5888],\n",
      "        [ 0.7026,  0.6647, -0.5864, -0.5164]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GraphConv\n",
    "\n",
    "# Define the GNN model\n",
    "class TwoAgentGNN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(TwoAgentGNN, self).__init__()\n",
    "        self.conv1 = GraphConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GraphConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x  # Output separate embeddings for each agent\n",
    "\n",
    "# Example input dimensions\n",
    "input_dim = 4\n",
    "hidden_dim = 16\n",
    "output_dim = 4\n",
    "\n",
    "# Instantiate the GNN\n",
    "gnn = TwoAgentGNN(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "obs1_sample = torch.randn(1,4)\n",
    "obs2_sample = torch.randn(1,4)\n",
    "x_batch = torch.cat([obs1_sample, obs2_sample], dim=0)\n",
    "\n",
    "print(x_batch)\n",
    "\n",
    "# # Example: obs1 and obs2 with shape (10000, 4)\n",
    "# obs1 = torch.randn(10000, 4)  # Replace with actual data\n",
    "# obs2 = torch.randn(10000, 4)  # Replace with actual data\n",
    "\n",
    "# # Stack observations to form a batch of agent pairs\n",
    "# x_batch = torch.cat([obs1, obs2], dim=0)  # Shape: (20000, 4)\n",
    "\n",
    "# # Define edge connections (same for all batches)\n",
    "edge_index = torch.tensor([[0, 1], [1, 0]], dtype=torch.long)  # Shape: (2, 2)\n",
    "\n",
    "# # Expand edge_index for batch processing\n",
    "# batch_size = obs1.shape[0]  # 10000\n",
    "# edge_index = edge_index.repeat(1, batch_size)  # Shape: (2, 2 * batch_size)\n",
    "\n",
    "# # Adjust node indices for batched graph (ensuring unique node indices per batch)\n",
    "# offsets = torch.arange(batch_size) * 2  # Offsets for each batch\n",
    "# edge_index = edge_index + offsets.repeat_interleave(2).unsqueeze(0)\n",
    "\n",
    "# # Forward pass through GNN\n",
    "# embeddings = gnn(x_batch, edge_index)  # Shape: (20000, 4)\n",
    "\n",
    "# # Reshape to separate agents\n",
    "# embeddings1, embeddings2 = embeddings.chunk(2, dim=0)  # Both shapes: (10000, 4)\n",
    "\n",
    "# print(\"Embeddings for Agent 1:\", embeddings1.shape)  # Expected: (10000, 4)\n",
    "# print(\"Embeddings for Agent 2:\", embeddings2.shape)  # Expected: (10000, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2865, -0.6232, -0.4839, -0.4187],\n",
       "        [ 0.5003,  0.0306, -0.9184,  0.1090]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnn(x_batch, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
